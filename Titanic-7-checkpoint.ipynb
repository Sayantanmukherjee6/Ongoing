{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from previous feature engineering , Here we are going to do :\n",
    "\n",
    "<li>1)Create salutations \n",
    "<li>2)Using the salutations we will calculate missing age values\n",
    "<li>3)We will create Family size and family using SIBSP and PARCH\n",
    "<li>4)We will create a new categorical Age Column based on Age\n",
    "<li>5)We are going t calculate Fare based on Passenger Class\n",
    "<li>6)Instead of Separate Male and Female column we will create a single Gender column\n",
    "<li>7)We will derive some new columns FPP,HighLow etc.. We are also going to include our previous feature engineering task whereever required(for eg : EMbarked)\n",
    "<li>8)Discarding Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=pd.read_csv('C:/Users/admin/Documents/Python Scripts/train.csv')\n",
    "#x.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title(name):\n",
    "    temp_1 = name.split(',') # Split by (,)\n",
    "    temp_2 = temp_1[1].split('.')[0] # Split by (.)\n",
    "    temp_3 = temp_2.strip() # Remove white space\n",
    "    return temp_3\n",
    "\n",
    "x['Title'] = x['Name'].apply(title)\n",
    "\n",
    "x ['Temp'] =x['Sex'] + x['Title'] #just for female doctors\n",
    "x.loc[x['Temp'] == 'femaleDr', 'Title'] = 'Mrs' #just for female doctors\n",
    "\n",
    "x.drop ([ 'Temp' ],axis =1 ,inplace= True) #just for female doctors\n",
    "\n",
    "def new_title(title):\n",
    "    if title == 'Mr' or title == 'Capt' or title == 'Don' or title == 'Dr' or title == 'Jonkheer' or title     == 'Major' or  title == 'Rev' or title == 'Sir' or title == 'Col':\n",
    "        return 'Mr'\n",
    "    elif title == 'Mrs' or title == 'Lady' or title == 'Mme' or title == 'Ms' or title == 'the       Countess':\n",
    "        return 'Mrs'\n",
    "    elif title == 'Miss' or title == 'Mlle':\n",
    "        return 'Miss'\n",
    "    else:\n",
    "        return 'Master'\n",
    "    \n",
    "x['NewTitle'] = x['Title'].apply(new_title)\n",
    "\n",
    "x.drop ([ 'Title' ],axis =1 ,inplace= True) # dropping some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating new family_size and family column\n",
    "x['Family_Size']=x['SibSp']+x['Parch']\n",
    "x['Family']=x['SibSp']*x['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imputing nan values of Fare based on Class\n",
    "x.loc[(x.Fare.isnull())&(x.Pclass==1),'Fare'] =np.median(x[x['Pclass'] == 1]['Fare'].dropna())\n",
    "x.loc[(x.Fare.isnull())&(x.Pclass==2),'Fare'] =np.median(x[x['Pclass'] == 2]['Fare'].dropna())\n",
    "x.loc[(x.Fare.isnull())&(x.Pclass==3),'Fare'] =np.median(x[x['Pclass'] == 3]['Fare'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#instead of male and female separate columns \n",
    "#    creating a single column based on gender\n",
    "x['Gender'] = x['Sex'].map( {'female': 0, 'male': 1} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imputing missing values of age based on salutations (Mr. ,Mrs Etc etc)\n",
    "x['AgeFill']=x['Age']\n",
    "mean_ages = np.zeros(4)\n",
    "mean_ages[0]=np.average(x[x['NewTitle'] == 'Miss']['Age'].dropna())\n",
    "mean_ages[1]=np.average(x[x['NewTitle'] == 'Mrs']['Age'].dropna())\n",
    "mean_ages[2]=np.average(x[x['NewTitle'] == 'Mr']['Age'].dropna())\n",
    "mean_ages[3]=np.average(x[x['NewTitle'] == 'Master']['Age'].dropna())\n",
    "x.loc[(x.Age.isnull()) & (x.NewTitle == 'Miss') ,'AgeFill'] = mean_ages[0]\n",
    "x.loc[(x.Age.isnull()) & (x.NewTitle == 'Mrs') ,'AgeFill'] = mean_ages[1]\n",
    "x.loc[(x.Age.isnull()) & (x.NewTitle == 'Mr') ,'AgeFill'] = mean_ages[2]\n",
    "x.loc[(x.Age.isnull()) & (x.NewTitle == 'Master') ,'AgeFill'] = mean_ages[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Based on age creating a categorical column \n",
    "\n",
    "x['AgeCat']=x['AgeFill']\n",
    "\n",
    "x.loc[(x.AgeFill<=12) ,'AgeCat'] = 'Child'\n",
    "x.loc[(x.AgeFill>49),'AgeCat'] = 'Senior'\n",
    "x.loc[(x.AgeFill>12) & (x.AgeFill <=19),'AgeCat'] = 'Teen'\n",
    "x.loc[(x.AgeFill>19) & (x.AgeFill <=49) ,'AgeCat'] = 'Adult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x['FPP']=x['Fare']/(x['Family_Size']+1) # FPP = Fare Per Passenger\n",
    "x['AgeClass']=x ['AgeFill']*x['Pclass']\n",
    "x['ClassFare']=x['Pclass']*x['FPP']\n",
    "\n",
    "x['HighLow']=x['Pclass']\n",
    "x.loc[ (x.FPP<8) ,'HighLow'] = 'Low'\n",
    "x.loc[ (x.FPP>=8) ,'HighLow'] = 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies1 = pd.get_dummies(x['NewTitle'], prefix = 'Title')\n",
    "x= pd.concat([x,dummies1],axis =1)\n",
    "\n",
    "dummies1 = pd.get_dummies(x['AgeCat'], prefix = 'Cat')\n",
    "x= pd.concat([x,dummies1],axis =1)\n",
    "\n",
    "dummies3 = pd.get_dummies(x['Embarked'], prefix = 'Embarked')\n",
    "x= pd.concat([x,dummies3],axis =1)\n",
    "\n",
    "dummies3 = pd.get_dummies(x['HighLow'], prefix = 'Class')\n",
    "x= pd.concat([x,dummies3],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#deleting unneccesary colmns\n",
    "x.drop (['Cabin','Name','Age','AgeCat','HighLow','SibSp','Parch','Ticket','NewTitle' ,'Sex','Embarked'],axis =1 ,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 24 columns):\n",
      "PassengerId     891 non-null int64\n",
      "Survived        891 non-null int64\n",
      "Pclass          891 non-null int64\n",
      "Fare            891 non-null float64\n",
      "Family_Size     891 non-null int64\n",
      "Family          891 non-null int64\n",
      "Gender          891 non-null int32\n",
      "AgeFill         891 non-null float64\n",
      "FPP             891 non-null float64\n",
      "AgeClass        891 non-null float64\n",
      "ClassFare       891 non-null float64\n",
      "Title_Master    891 non-null float64\n",
      "Title_Miss      891 non-null float64\n",
      "Title_Mr        891 non-null float64\n",
      "Title_Mrs       891 non-null float64\n",
      "Cat_Adult       891 non-null float64\n",
      "Cat_Child       891 non-null float64\n",
      "Cat_Senior      891 non-null float64\n",
      "Cat_Teen        891 non-null float64\n",
      "Embarked_C      891 non-null float64\n",
      "Embarked_Q      891 non-null float64\n",
      "Embarked_S      891 non-null float64\n",
      "Class_High      891 non-null float64\n",
      "Class_Low       891 non-null float64\n",
      "dtypes: float64(18), int32(1), int64(5)\n",
      "memory usage: 170.5 KB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Doing The Same Stuff For Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtest = pd.read_csv('C:/Users/admin/Documents/Python Scripts/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title(name):\n",
    "    temp_1 = name.split(',') # Split by (,)\n",
    "    temp_2 = temp_1[1].split('.')[0] # Split by (.)\n",
    "    temp_3 = temp_2.strip() # Remove white space\n",
    "    return temp_3\n",
    "\n",
    "xtest['Title'] = xtest['Name'].apply(title)\n",
    "\n",
    "def new_title(title):\n",
    "    if title == 'Mr' or title == 'Capt' or title == 'Don' or title == 'Dr' or title == 'Jonkheer' or title == 'Major' or  title == 'Rev' or title == 'Sir' or title == 'Col':\n",
    "        return 'Mr'\n",
    "    elif title == 'Mrs' or title == 'Lady' or title == 'Mme' or title == 'Ms' or title == 'the       Countess':\n",
    "        return 'Mrs'\n",
    "    elif title == 'Miss' or title == 'Mlle':\n",
    "        return 'Miss'\n",
    "    else:\n",
    "        return 'Master'\n",
    "    \n",
    "xtest['NewTitle'] = xtest['Title'].apply(new_title)\n",
    "xtest.drop ([ 'Title' ],axis =1 ,inplace= True) # dropping some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating new family_size and family column\n",
    "xtest['Family_Size']=xtest['SibSp']+xtest['Parch']\n",
    "xtest['Family']=xtest['SibSp']*xtest['Parch']\n",
    "\n",
    "#imputing nan values of Fare based on Class\n",
    "xtest.loc[(xtest.Fare.isnull())&(xtest.Pclass==1),'Fare'] =np.median(xtest[xtest['Pclass'] == 1]['Fare'].dropna())\n",
    "xtest.loc[(xtest.Fare.isnull())&(xtest.Pclass==2),'Fare'] =np.median(xtest[xtest['Pclass'] == 2]['Fare'].dropna())\n",
    "xtest.loc[(xtest.Fare.isnull())&(xtest.Pclass==3),'Fare'] =np.median(xtest[xtest['Pclass'] == 3]['Fare'].dropna())\n",
    "\n",
    "xtest['Gender'] = xtest['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "xtest['AgeFill']=xtest['Age']\n",
    "mean_ages = np.zeros(4)\n",
    "mean_ages[0]=np.average(xtest[xtest['NewTitle']  == 'Miss']['Age'].dropna())\n",
    "mean_ages[1]=np.average(xtest[xtest['NewTitle']  == 'Mrs']['Age'].dropna())\n",
    "mean_ages[2]=np.average(xtest[xtest['NewTitle']  == 'Mr']['Age'].dropna())\n",
    "mean_ages[3]=np.average(xtest[xtest['NewTitle']  == 'Master']['Age'].dropna())\n",
    "xtest.loc[(xtest.Age.isnull()) & (xtest.NewTitle == 'Miss') ,'AgeFill'] = mean_ages[0]\n",
    "xtest.loc[(xtest.Age.isnull()) & (xtest.NewTitle == 'Mrs') ,'AgeFill'] = mean_ages[1]\n",
    "xtest.loc[(xtest.Age.isnull()) & (xtest.NewTitle == 'Mr') ,'AgeFill'] = mean_ages[2]\n",
    "xtest.loc[(xtest.Age.isnull()) & (xtest.NewTitle == 'Master') ,'AgeFill'] = mean_ages[3]\n",
    "\n",
    "xtest['AgeCat']=xtest['AgeFill']\n",
    "xtest.loc[(xtest.AgeFill<=12) ,'AgeCat'] = 'Child'\n",
    "xtest.loc[(xtest.AgeFill>49),'AgeCat'] = 'Senior'\n",
    "xtest.loc[(xtest.AgeFill>12) & (xtest.AgeFill <=19),'AgeCat'] = 'Teen'\n",
    "xtest.loc[(xtest.AgeFill>19) & (xtest.AgeFill <=49) ,'AgeCat'] = 'Adult'\n",
    "\n",
    "xtest['FPP']=xtest['Fare']/(xtest['Family_Size']+1) # FPP = Fare Per Passenger\n",
    "xtest['AgeClass']=xtest['AgeFill']*xtest['Pclass']\n",
    "xtest['ClassFare']=xtest['Pclass']*xtest['FPP']\n",
    "\n",
    "xtest['HighLow']=xtest['Pclass']\n",
    "xtest.loc[(xtest.FPP<8) ,'HighLow'] = 'Low'\n",
    "xtest.loc[(xtest.FPP>=8) ,'HighLow'] = 'High'\n",
    "\n",
    "dummies1 = pd.get_dummies(xtest['NewTitle'], prefix = 'Title')\n",
    "xtest= pd.concat([xtest,dummies1],axis =1)\n",
    "\n",
    "dummies1 = pd.get_dummies(xtest['AgeCat'], prefix = 'Cat')\n",
    "xtest= pd.concat([xtest,dummies1],axis =1)\n",
    "\n",
    "dummies3 = pd.get_dummies(xtest['Embarked'], prefix = 'Embarked')\n",
    "xtest= pd.concat([xtest,dummies3],axis =1)\n",
    "\n",
    "dummies3 = pd.get_dummies(xtest['HighLow'], prefix = 'Class')\n",
    "xtest= pd.concat([xtest,dummies3],axis =1)\n",
    "\n",
    "xtest.drop (['Name','Cabin','Age','AgeCat','HighLow','SibSp','Parch','Ticket','NewTitle' ,'Sex','Embarked'],axis =1 ,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 23)\n",
      "(418, 23)\n"
     ]
    }
   ],
   "source": [
    "y=x.pop('Survived')\n",
    "print (x.shape)\n",
    "print (xtest.shape)\n",
    "#xtest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Feature Engineering Complete.. Next Classification & Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1=x\n",
    "y1=y\n",
    "xtest1=xtest\n",
    "\n",
    "train=x.values\n",
    "target=y.values\n",
    "test=xtest.values\n",
    "\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score,KFold,StratifiedShuffleSplit,StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.783217 -   0.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.867133 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.825175 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.825175 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.881119 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.839161 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.846154 -   0.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.832168 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.832168 -   0.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.839161 -   0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=5, min_samples_split=1,\n",
    "  min_samples_leaf=1, max_features='auto',bootstrap=False,n_jobs=1, random_state=42,\n",
    "  verbose=0, min_density=None, compute_importances=None)\n",
    "\n",
    "###compute grid search to find best paramters for pipeline\n",
    "param_grid = dict( )\n",
    "##classify pipeline\n",
    "pipeline=Pipeline([ ('clf',clf) ])\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=3,scoring='accuracy',\\\n",
    "cv=StratifiedShuffleSplit(y_train, n_iter=10, test_size=0.2, train_size=None, indices=None, \\\n",
    "random_state=42, n_iterations=None)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.852\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'max_features': [0.5, 1.],\n",
    "    'max_depth': [5., None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(min_samples_leaf=1,bootstrap=False,n_jobs=-1,min_samples_split=1,random_state=42,n_estimators = 500,criterion='entropy'), parameter_grid,cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.818182 -   0.6s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.832168 -   0.6s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.823944 -   0.6s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.887324 -   0.6s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.908451 -   0.6s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.783217 -   0.8s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.797203 -   0.7s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.788732 -   0.8s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.866197 -   0.8s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.859155 -   0.8s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.783217 -   0.7s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.818182 -   0.7s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.767606 -   0.7s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.823944 -   0.7s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.866197 -   0.7s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.734266 -   1.0s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.776224 -   0.9s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.746479 -   0.9s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.838028 -   1.0s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.830986 -   0.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   17.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "       estimator=RandomForestClassifier(bootstrap=False, compute_importances=None,\n",
       "            criterion='entropy', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
       "            min_samples_split=1, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'max_features': [0.5, 1.0], 'max_depth': [5.0, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=3)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5.0, 'max_features': 0.5}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "grid_search.best_score_\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.837988826816\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf=RandomForestClassifier(n_estimators=500, \n",
    "                           criterion='gini',\n",
    "                           max_depth=5,\n",
    "                           min_samples_split=1,\n",
    "                           min_samples_leaf=1,\n",
    "                           max_features=0.5,\n",
    "                           bootstrap=False,n_jobs=-1, \n",
    "                           random_state=42,\n",
    "                           verbose=0, \n",
    "                           min_density=None, \n",
    "                           compute_importances=None)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=100, \n",
    "                           criterion='gini',\n",
    "                           max_depth=7,\n",
    "                           min_samples_split=0.5,\n",
    "                           min_samples_leaf=14,\n",
    "                           max_features=0.5,\n",
    "                           n_jobs=-1, \n",
    "                           random_state=42,)\n",
    "                           \n",
    "\n",
    "clf = clf.fit(train,target)\n",
    "clf_test_predict = clf.predict(test)\n",
    "xtest1['Survived'] = clf_test_predict\n",
    "xtest1[['PassengerId','Survived']].to_csv('M21.csv', index=False, float_format=\"%f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793296089385\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel ='linear',C=1.0,gamma =0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793296089385\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel ='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel ='linear',C=1,gamma=0.3)\n",
    "clf = clf.fit(train,target)\n",
    "clf_test_predict = clf.predict(test)\n",
    "xtest1['Survived'] = clf_test_predict\n",
    "xtest1[['PassengerId','Survived']].to_csv('M15.csv', index=False, float_format=\"%f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Evaluating models using KFolD Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822718193168\n"
     ]
    }
   ],
   "source": [
    "# 10 Fold Cross Validation with Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "print cross_val_score(logreg,x,y,cv=10,scoring ='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66448473499\n"
     ]
    }
   ],
   "source": [
    "# 10 Fold Cross Validation with KNN for n=52\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=52)\n",
    "print cross_val_score(knn,x,y,cv=10,scoring ='accuracy').mean()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.837249744637\n"
     ]
    }
   ],
   "source": [
    "# 10 Fold Cross Validation with Random Forest with gini score\n",
    "clf=RandomForestClassifier(n_estimators=1000, \n",
    "                           criterion='gini',\n",
    "                           max_depth=5,\n",
    "                           min_samples_split=1,\n",
    "                           min_samples_leaf=1,\n",
    "                           max_features=0.5,\n",
    "                           bootstrap=False,n_jobs=-1, \n",
    "                           random_state=42,\n",
    "                           verbose=0, \n",
    "                           min_density=None, \n",
    "                           compute_importances=None)\n",
    "\n",
    "print cross_val_score(clf,x,y,cv=10,scoring ='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845152933833\n"
     ]
    }
   ],
   "source": [
    "# 10 Fold Cross Validation with Random Forest with entropy\n",
    "clf=RandomForestClassifier(n_estimators=500, \n",
    "                           criterion='entropy',\n",
    "                           max_depth=5,\n",
    "                           min_samples_split=1,\n",
    "                           min_samples_leaf=10,\n",
    "                           max_features=0.5,\n",
    "                           bootstrap=False,n_jobs=-1, \n",
    "                           random_state=42,\n",
    "                           verbose=0, \n",
    "                           min_density=None, \n",
    "                           compute_importances=None)\n",
    "\n",
    "print cross_val_score(clf,x,y,cv=10,scoring ='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827137101351\n"
     ]
    }
   ],
   "source": [
    "# 10 Fold Cross Validation with SVM with Linear Kernel\n",
    "clf = svm.SVC(kernel ='linear',C=1,gamma=0.3)\n",
    "print cross_val_score(clf,x,y,cv=10,scoring ='accuracy').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
