{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> Braund, Mr. Owen Harris</td>\n",
       "      <td> male</td>\n",
       "      <td> 22</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> A/5 21171</td>\n",
       "      <td> 7.25</td>\n",
       "      <td> NaN</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                     Name   Sex  Age  SibSp  \\\n",
       "0            1         0       3  Braund, Mr. Owen Harris  male   22      1   \n",
       "\n",
       "   Parch     Ticket  Fare Cabin Embarked  \n",
       "0      0  A/5 21171  7.25   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=pd.read_csv('train.csv')\n",
    "xtest = pd.read_csv('test.csv')\n",
    "x.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 892</td>\n",
       "      <td> 3</td>\n",
       "      <td> Kelly, Mr. James</td>\n",
       "      <td> male</td>\n",
       "      <td> 34.5</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 330911</td>\n",
       "      <td> 7.8292</td>\n",
       "      <td> U</td>\n",
       "      <td> Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass              Name   Sex   Age  SibSp  Parch  Ticket  \\\n",
       "0          892       3  Kelly, Mr. James  male  34.5      0      0  330911   \n",
       "\n",
       "     Fare Cabin Embarked  \n",
       "0  7.8292     U        Q  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doing the same thing as we have done using Re ...\n",
    "def clean_cabin(x):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except TypeError:\n",
    "        return \"U\"\n",
    "    \n",
    "x['Cabin'] = x.Cabin.apply(clean_cabin)\n",
    "\n",
    "def clean_cabin(x):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except TypeError:\n",
    "        return \"U\"\n",
    "    \n",
    "xtest['Cabin'] = xtest.Cabin.apply(clean_cabin)\n",
    "\n",
    "xtest.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.loc[(x['Pclass'] == 1) & (x['Cabin'] == 'U'), 'Cabin'] = 'C'\n",
    "x.loc[(x['Pclass'] == 2) & (x['Cabin'] == 'U'), 'Cabin'] = 'E'\n",
    "x.loc[(x['Pclass'] == 3) & (x['Cabin'] == 'U') & (x['Sex'] == 'male') , 'Cabin'] = 'F'\n",
    "x.loc[(x['Pclass'] == 3) & (x['Cabin'] == 'U') & (x['Sex'] == 'female'),'Cabin'] = 'G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtest.loc[(xtest['Pclass'] == 1) & (xtest['Cabin'] == 'U'), 'Cabin'] = 'C'\n",
    "xtest.loc[(xtest['Pclass'] == 2) & (xtest['Cabin'] == 'U'), 'Cabin'] = 'E'\n",
    "xtest.loc[(xtest['Pclass'] == 3) & (xtest['Cabin'] == 'U') & (xtest['Sex'] == 'male') , 'Cabin'] = 'F'\n",
    "xtest.loc[(xtest['Pclass'] == 3) & (xtest['Cabin'] == 'U') & (xtest['Sex'] == 'female'),'Cabin'] = 'G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(x['Cabin'], prefix = 'Deck')\n",
    "x= pd.concat([x,dummies],axis =1)\n",
    "\n",
    "x.drop (['Deck_T'],axis =1 ,inplace= True)\n",
    "\n",
    "dummies = pd.get_dummies(xtest['Cabin'], prefix = 'Deck')\n",
    "xtest= pd.concat([xtest,dummies],axis =1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def title(name):\n",
    "    temp_1 = name.split(',') # Split by (,)\n",
    "    temp_2 = temp_1[1].split('.')[0] # Split by (.)\n",
    "    temp_3 = temp_2.strip() # Remove white space\n",
    "    return temp_3\n",
    "\n",
    "x['Title'] = x['Name'].apply(title)\n",
    "\n",
    "x ['Temp'] =x['Sex'] + x['Title'] #just for female doctors\n",
    "x.loc[x['Temp'] == 'femaleDr', 'Title'] = 'Mrs' #just for female doctors\n",
    "\n",
    "x.drop ([ 'Temp' ],axis =1 ,inplace= True) #just for female doctors\n",
    "\n",
    "def new_title(title):\n",
    "    if title == 'Mr' or title == 'Capt' or title == 'Don' or title == 'Dr' or title == 'Jonkheer' or title     == 'Major' or  title == 'Rev' or title == 'Sir' or title == 'Col':\n",
    "        return 'Mr'\n",
    "    elif title == 'Mrs' or title == 'Lady' or title == 'Mme' or title == 'Ms' or title == 'the       Countess':\n",
    "        return 'Mrs'\n",
    "    elif title == 'Miss' or title == 'Mlle':\n",
    "        return 'Miss'\n",
    "    else:\n",
    "        return 'Master'\n",
    "    \n",
    "x['NewTitle'] = x['Title'].apply(new_title)\n",
    "\n",
    "x.drop ([ 'Title' ],axis =1 ,inplace= True) # dropping some columns\n",
    "\n",
    "#Creating new family_size and family column\n",
    "x['Family_Size']=x['SibSp']+x['Parch']\n",
    "x['Family']=x['SibSp']*x['Parch']\n",
    "\n",
    "#imputing nan values of Fare based on Class\n",
    "x.loc[(x.Fare.isnull())&(x.Pclass==1),'Fare'] =np.median(x[x['Pclass'] == 1]['Fare'].dropna())\n",
    "x.loc[(x.Fare.isnull())&(x.Pclass==2),'Fare'] =np.median(x[x['Pclass'] == 2]['Fare'].dropna())\n",
    "x.loc[(x.Fare.isnull())&(x.Pclass==3),'Fare'] =np.median(x[x['Pclass'] == 3]['Fare'].dropna())\n",
    "\n",
    "#instead of male and female separate columns \n",
    "#    creating a single column based on gender\n",
    "x['Gender'] = x['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "x.Embarked[ x.Embarked.isnull() ] = x.Embarked.dropna().mode().values\n",
    "\n",
    "#imputing missing values of age based on salutations (Mr. ,Mrs Etc etc)\n",
    "x['AgeFill']=x['Age']\n",
    "mean_ages = np.zeros(4)\n",
    "mean_ages[0]=np.average(x[x['NewTitle'] == 'Miss']['Age'].dropna())\n",
    "mean_ages[1]=np.average(x[x['NewTitle'] == 'Mrs']['Age'].dropna())\n",
    "mean_ages[2]=np.average(x[x['NewTitle'] == 'Mr']['Age'].dropna())\n",
    "mean_ages[3]=np.average(x[x['NewTitle'] == 'Master']['Age'].dropna())\n",
    "x.loc[(x.Age.isnull()) & (x.NewTitle == 'Miss') ,'AgeFill'] = mean_ages[0]\n",
    "x.loc[(x.Age.isnull()) & (x.NewTitle == 'Mrs') ,'AgeFill'] = mean_ages[1]\n",
    "x.loc[(x.Age.isnull()) & (x.NewTitle == 'Mr') ,'AgeFill'] = mean_ages[2]\n",
    "x.loc[(x.Age.isnull()) & (x.NewTitle == 'Master') ,'AgeFill'] = mean_ages[3]\n",
    "\n",
    "#Based on age creating a categorical column \n",
    "\n",
    "x['AgeCat']=x['AgeFill']\n",
    "\n",
    "x.loc[(x.AgeFill<=12) ,'AgeCat'] = 'Child'\n",
    "x.loc[(x.AgeFill>49),'AgeCat'] = 'Senior'\n",
    "x.loc[(x.AgeFill>12) & (x.AgeFill <=19),'AgeCat'] = 'Teen'\n",
    "x.loc[(x.AgeFill>19) & (x.AgeFill <=49) ,'AgeCat'] = 'Adult'\n",
    "\n",
    "x['FPP']=x['Fare']/(x['Family_Size']+1) # FPP = Fare Per Passenger\n",
    "x['AgeClass']=x ['AgeFill']*x['Pclass']\n",
    "x['ClassFare']=x['Pclass']*x['FPP']\n",
    "\n",
    "x['HighLow']=x['Pclass']\n",
    "x.loc[ (x.FPP<8) ,'HighLow'] = 'Low'\n",
    "x.loc[ (x.FPP>=8) ,'HighLow'] = 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 22 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "Embarked       891 non-null object\n",
      "Deck_A         891 non-null float64\n",
      "Deck_B         891 non-null float64\n",
      "Deck_C         891 non-null float64\n",
      "Deck_D         891 non-null float64\n",
      "Deck_E         891 non-null float64\n",
      "Deck_F         891 non-null float64\n",
      "Deck_G         891 non-null float64\n",
      "NewTitle       891 non-null object\n",
      "Family_Size    891 non-null int64\n",
      "Family         891 non-null int64\n",
      "Gender         891 non-null int32\n",
      "AgeFill        891 non-null float64\n",
      "AgeCat         891 non-null object\n",
      "FPP            891 non-null float64\n",
      "AgeClass       891 non-null float64\n",
      "ClassFare      891 non-null float64\n",
      "HighLow        891 non-null object\n",
      "dtypes: float64(12), int32(1), int64(5), object(4)\n",
      "memory usage: 156.6+ KB\n"
     ]
    }
   ],
   "source": [
    "x.drop (['Cabin','Name','Age','SibSp','Parch','Ticket' ,'Sex'],axis =1 ,inplace= True)\n",
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature transformation without creating more features\n",
    "\n",
    "x['Embarked'] = x['Embarked'].map({'C':1, 'S':2, 'Q':3}).astype(int) \n",
    "x['NewTitle'] = x['NewTitle'].map({'Mr':1, 'Mrs':2, 'Master':3, 'Miss':4}).astype(int)\n",
    "x['AgeCat'] = x['AgeCat'].map({'Child':1, 'Teen':2, 'Adult':3, 'Senior':4}).astype(int)\n",
    "x['HighLow'] = x['HighLow'].map({'Low':0, 'High':1}).astype(int)\n",
    "\n",
    "#Feature Normalization : fare,agefill,Fpp,ageclass,classfare\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "x['FPP_Scaled'] = scaler.fit_transform(x['FPP'])\n",
    "x['Age_Scaled'] = scaler.fit_transform(x['AgeFill'])\n",
    "x['Fare_Scaled'] = scaler.fit_transform(x['Fare'])\n",
    "x['Age_Class'] = scaler.fit_transform(x['AgeClass'])\n",
    "x['Class_Fare'] = scaler.fit_transform(x['ClassFare'])\n",
    "\n",
    "x.drop (['FPP','AgeFill','Fare','AgeClass','ClassFare'],axis =1 ,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Deck_A</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Family</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeCat</th>\n",
       "      <th>HighLow</th>\n",
       "      <th>FPP_Scaled</th>\n",
       "      <th>Age_Scaled</th>\n",
       "      <th>Fare_Scaled</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Class_Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>...</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.007076</td>\n",
       "      <td> 0.271174</td>\n",
       "      <td> 0.014151</td>\n",
       "      <td> 0.294373</td>\n",
       "      <td> 0.021227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Embarked  Deck_A  Deck_B  Deck_C  Deck_D  \\\n",
       "0            1         0       3         2       0       0       0       0   \n",
       "\n",
       "   Deck_E  Deck_F     ...      Family_Size  Family  Gender  AgeCat  HighLow  \\\n",
       "0       0       1     ...                1       0       1       3        0   \n",
       "\n",
       "   FPP_Scaled  Age_Scaled  Fare_Scaled  Age_Class  Class_Fare  \n",
       "0    0.007076    0.271174     0.014151   0.294373    0.021227  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def title(name):\n",
    "    temp_1 = name.split(',') # Split by (,)\n",
    "    temp_2 = temp_1[1].split('.')[0] # Split by (.)\n",
    "    temp_3 = temp_2.strip() # Remove white space\n",
    "    return temp_3\n",
    "\n",
    "xtest['Title'] = xtest['Name'].apply(title)\n",
    "def new_title(title):\n",
    "    if title == 'Mr' or title == 'Capt' or title == 'Don' or title == 'Dr' or title == 'Jonkheer' or title     == 'Major' or  title == 'Rev' or title == 'Sir' or title == 'Col':\n",
    "        return 'Mr'\n",
    "    elif title == 'Mrs' or title == 'Lady' or title == 'Mme' or title == 'Ms' or title == 'the       Countess':\n",
    "        return 'Mrs'\n",
    "    elif title == 'Miss' or title == 'Mlle':\n",
    "        return 'Miss'\n",
    "    else:\n",
    "        return 'Master'\n",
    "    \n",
    "xtest['NewTitle'] = xtest['Title'].apply(new_title)\n",
    "\n",
    "xtest.drop ([ 'Title' ],axis =1 ,inplace= True) # dropping some columns\n",
    "\n",
    "#Creating new family_size and family column\n",
    "xtest['Family_Size']=xtest['SibSp']+xtest['Parch']\n",
    "xtest['Family']=xtest['SibSp']*xtest['Parch']\n",
    "\n",
    "#imputing nan values of Fare based on Class\n",
    "xtest.loc[(xtest.Fare.isnull())&(xtest.Pclass==1),'Fare'] =np.median(xtest[xtest['Pclass'] == 1]['Fare'].dropna())\n",
    "xtest.loc[(xtest.Fare.isnull())&(xtest.Pclass==2),'Fare'] =np.median(xtest[xtest['Pclass'] == 2]['Fare'].dropna())\n",
    "xtest.loc[(xtest.Fare.isnull())&(xtest.Pclass==3),'Fare'] =np.median(xtest[xtest['Pclass'] == 3]['Fare'].dropna())\n",
    "\n",
    "#instead of male and female separate columns \n",
    "#    creating a single column based on gender\n",
    "xtest['Gender'] = xtest['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "xtest.Embarked[xtest.Embarked.isnull()] = xtest.Embarked.dropna().mode().values\n",
    "\n",
    "#imputing missing values of age based on salutations (Mr. ,Mrs Etc etc)\n",
    "xtest['AgeFill']=xtest['Age']\n",
    "mean_ages = np.zeros(4)\n",
    "mean_ages[0]=np.average(xtest[xtest['NewTitle'] == 'Miss']['Age'].dropna())\n",
    "mean_ages[1]=np.average(xtest[xtest['NewTitle'] == 'Mrs']['Age'].dropna())\n",
    "mean_ages[2]=np.average(xtest[xtest['NewTitle'] == 'Mr']['Age'].dropna())\n",
    "mean_ages[3]=np.average(xtest[xtest['NewTitle'] == 'Master']['Age'].dropna())\n",
    "xtest.loc[(xtest.Age.isnull()) & (xtest.NewTitle == 'Miss') ,'AgeFill'] = mean_ages[0]\n",
    "xtest.loc[(xtest.Age.isnull()) & (xtest.NewTitle == 'Mrs') ,'AgeFill'] = mean_ages[1]\n",
    "xtest.loc[(xtest.Age.isnull()) & (xtest.NewTitle == 'Mr') ,'AgeFill'] = mean_ages[2]\n",
    "xtest.loc[(xtest.Age.isnull()) & (xtest.NewTitle == 'Master') ,'AgeFill'] = mean_ages[3]\n",
    "\n",
    "#Based on age creating a categorical column \n",
    "\n",
    "xtest['AgeCat']=xtest['AgeFill']\n",
    "\n",
    "xtest.loc[(xtest.AgeFill<=12) ,'AgeCat'] = 'Child'\n",
    "xtest.loc[(xtest.AgeFill>49),'AgeCat'] = 'Senior'\n",
    "xtest.loc[(xtest.AgeFill>12) & (xtest.AgeFill <=19),'AgeCat'] = 'Teen'\n",
    "xtest.loc[(xtest.AgeFill>19) & (xtest.AgeFill <=49) ,'AgeCat'] = 'Adult'\n",
    "\n",
    "xtest['FPP']=xtest['Fare']/(xtest['Family_Size']+1) # FPP = Fare Per Passenger\n",
    "xtest['AgeClass']=xtest['AgeFill']*xtest['Pclass']\n",
    "xtest['ClassFare']=xtest['Pclass']*xtest['FPP']\n",
    "\n",
    "xtest['HighLow']=xtest['Pclass']\n",
    "xtest.loc[(xtest.FPP<8) ,'HighLow'] = 'Low'\n",
    "xtest.loc[(xtest.FPP>=8) ,'HighLow'] = 'High'\n",
    "\n",
    "xtest.drop (['Cabin','Name','Age','SibSp','Parch','Ticket' ,'Sex'],axis =1 ,inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature transformation without creating more features\n",
    "\n",
    "xtest['Embarked'] = xtest['Embarked'].map({'C':1, 'S':2, 'Q':3}).astype(int) \n",
    "xtest['NewTitle'] = xtest['NewTitle'].map({'Mr':1, 'Mrs':2, 'Master':3, 'Miss':4}).astype(int)\n",
    "xtest['AgeCat'] = xtest['AgeCat'].map({'Child':1, 'Teen':2, 'Adult':3, 'Senior':4}).astype(int)\n",
    "xtest['HighLow'] = xtest['HighLow'].map({'Low':0, 'High':1}).astype(int)\n",
    "\n",
    "#Feature Normalization : fare,agefill,Fpp,ageclass,classfare\n",
    "scaler_test = preprocessing.MinMaxScaler()\n",
    "\n",
    "xtest['FPP_Scaled'] = scaler_test.fit_transform(xtest['FPP'])\n",
    "xtest['Age_Scaled'] = scaler_test.fit_transform(xtest['AgeFill'])\n",
    "xtest['Fare_Scaled'] = scaler_test.fit_transform(xtest['Fare'])\n",
    "xtest['Age_Class'] = scaler_test.fit_transform(xtest['AgeClass'])\n",
    "xtest['Class_Fare'] = scaler_test.fit_transform(xtest['ClassFare'])\n",
    "\n",
    "xtest.drop (['FPP','AgeFill','Fare','AgeClass','ClassFare'],axis =1 ,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Deck_A</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Family</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeCat</th>\n",
       "      <th>HighLow</th>\n",
       "      <th>FPP_Scaled</th>\n",
       "      <th>Age_Scaled</th>\n",
       "      <th>Fare_Scaled</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Class_Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>...</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.007076</td>\n",
       "      <td> 0.271174</td>\n",
       "      <td> 0.014151</td>\n",
       "      <td> 0.294373</td>\n",
       "      <td> 0.021227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Embarked  Deck_A  Deck_B  Deck_C  Deck_D  \\\n",
       "0            1         0       3         2       0       0       0       0   \n",
       "\n",
       "   Deck_E  Deck_F     ...      Family_Size  Family  Gender  AgeCat  HighLow  \\\n",
       "0       0       1     ...                1       0       1       3        0   \n",
       "\n",
       "   FPP_Scaled  Age_Scaled  Fare_Scaled  Age_Class  Class_Fare  \n",
       "0    0.007076    0.271174     0.014151   0.294373    0.021227  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Deck_A</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>Deck_G</th>\n",
       "      <th>...</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Family</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeCat</th>\n",
       "      <th>HighLow</th>\n",
       "      <th>FPP_Scaled</th>\n",
       "      <th>Age_Scaled</th>\n",
       "      <th>Fare_Scaled</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Class_Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 892</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.02984</td>\n",
       "      <td> 0.452723</td>\n",
       "      <td> 0.015282</td>\n",
       "      <td> 0.569037</td>\n",
       "      <td> 0.089519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Embarked  Deck_A  Deck_B  Deck_C  Deck_D  Deck_E  \\\n",
       "0          892       3         3       0       0       0       0       0   \n",
       "\n",
       "   Deck_F  Deck_G     ...      Family_Size  Family  Gender  AgeCat  HighLow  \\\n",
       "0       1       0     ...                0       0       1       3        0   \n",
       "\n",
       "   FPP_Scaled  Age_Scaled  Fare_Scaled  Age_Class  Class_Fare  \n",
       "0     0.02984    0.452723     0.015282   0.569037    0.089519  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 21)\n",
      "(418, 21)\n"
     ]
    }
   ],
   "source": [
    "y=x.pop('Survived')\n",
    "print (x.shape)\n",
    "print (xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1=x\n",
    "y1=y\n",
    "xtest1=xtest\n",
    "\n",
    "train=x.values\n",
    "target=y.values\n",
    "test=xtest.values\n",
    "\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score,KFold,StratifiedShuffleSplit,StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833916411304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=500, \n",
    "                           criterion='gini',\n",
    "                           max_depth=5,\n",
    "                           min_samples_split=1,\n",
    "                           min_samples_leaf=1,\n",
    "                           max_features=0.5,\n",
    "                           bootstrap=False,n_jobs=-1, \n",
    "                           random_state=42,\n",
    "                           verbose=0, \n",
    "                           min_density=None, \n",
    "                           compute_importances=None)\n",
    "\n",
    "#clf.fit(X_train, y_train)\n",
    "#y_pred = clf.predict(X_test)\n",
    "#print metrics.accuracy_score(y_test, y_pred) # accuracy = 0.86592178\n",
    "print cross_val_score(clf,x,y,cv=10,scoring ='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841781296107\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "clf=RandomForestClassifier(n_estimators=1000, \n",
    "                           criterion='gini',\n",
    "                           max_depth=5,\n",
    "                           min_samples_split=1,\n",
    "                           min_samples_leaf=1,\n",
    "                           max_features=0.5,\n",
    "                           bootstrap=False,n_jobs=-1, \n",
    "                           random_state=42,\n",
    "                           verbose=0, \n",
    "                           min_density=None, \n",
    "                           compute_importances=None)\n",
    "                           '''\n",
    "rnn = RandomForestClassifier(random_state=1, n_estimators=175, min_samples_split=4, min_samples_leaf=2)\n",
    "\n",
    "print cross_val_score(rnn,x,y,cv=10,scoring ='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=250, \n",
    "                           criterion='entropy',\n",
    "                           max_depth=5,\n",
    "                           min_samples_split=1,\n",
    "                           min_samples_leaf=9,\n",
    "                           max_features=0.5,\n",
    "                           bootstrap=False,n_jobs=-1, \n",
    "                           random_state=42,\n",
    "                           verbose=0, \n",
    "                           min_density=None, \n",
    "                           compute_importances=None)\n",
    "clf = clf.fit(train,target)\n",
    "clf_test_predict = clf.predict(test)\n",
    "xtest1['Survived'] = clf_test_predict\n",
    "xtest1[['PassengerId','Survived']].to_csv('M19.csv', index=False, float_format=\"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815642458101\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel ='linear',C=1,gamma=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel ='linear',C=1,gamma=0.3)\n",
    "clf = clf.fit(train,target)\n",
    "clf_test_predict = clf.predict(test)\n",
    "xtest1['Survived'] = clf_test_predict\n",
    "xtest1[['PassengerId','Survived']].to_csv('M17.csv', index=False, float_format=\"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel ='linear',C=1,gamma=0.1)\n",
    "clf = clf.fit(train,target)\n",
    "clf_test_predict = clf.predict(test)\n",
    "xtest1['Survived'] = clf_test_predict\n",
    "xtest1[['PassengerId','Survived']].to_csv('M18.csv', index=False, float_format=\"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.804469273743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=90)\n",
    "clf.fit(X_train, y_train)\n",
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=90)\n",
    "clf = clf.fit(train,target)\n",
    "clf_test_predict = clf.predict(test)\n",
    "xtest1['Survived'] = clf_test_predict\n",
    "xtest1[['PassengerId','Survived']].to_csv('M19.csv', index=False, float_format=\"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798882681564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf = clf.fit(train,target)\n",
    "clf_test_predict = clf.predict(test)\n",
    "xtest1['Survived'] = clf_test_predict\n",
    "xtest1[['PassengerId','Survived']].to_csv('M20.csv', index=False, float_format=\"%f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Searching for best Hyperparameter in Random Forest using Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [35, 40, 42, 45, 50, 53, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 125, 150], 'random_state': [35, 40, 42, 45, 50, 53, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 125, 150]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "#e_range = (100,200)\n",
    "c_options=['gini','entropy']\n",
    "feature_option=['auto','sqrt',0.5]\n",
    "depth_option = [0.5,5,7,9,None]\n",
    "split_option = [1,4,7,9,11]\n",
    "leaf_options=[1,4,7,9,11]\n",
    "param_grid = dict(criterion = c_options,\n",
    "                  max_features=feature_option,\n",
    "                  max_depth=depth_option,\n",
    "                  min_samples_split=split_option,\n",
    "                  min_samples_leaf =leaf_options\n",
    "                  #n_estimators= e_range)                  \n",
    "print param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "'''\n",
    "grid_clf = RandomForestClassifier(criterion='entropy',\n",
    "                                  max_depth=None,\n",
    "                                  min_samples_split=1,\n",
    "                                  min_samples_leaf=11,\n",
    "                                  max_features=0.5,\n",
    "                                  n_jobs=-1, \n",
    "                                  random_state=42,\n",
    "                                  min_density=None)\n",
    "                                  '''\n",
    "grid_clf = RandomForestClassifier(n_estimators= 75,random_state=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid =GridSearchCV(grid_clf,param_grid,cv=8,scoring ='accuracy',n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#After running grid score and everything in my tab i got a whooping 81 percent score\n",
    "clf=RandomForestClassifier(n_estimators=75, \n",
    "                           criterion='entropy',\n",
    "                           max_depth=None,\n",
    "                           min_samples_split=1,\n",
    "                           min_samples_leaf=11,\n",
    "                           max_features=0.5,\n",
    "                           n_jobs=-1, \n",
    "                           random_state=80,\n",
    "                           min_density=None)\n",
    "clf = clf.fit(train,target)\n",
    "clf_test_predict = clf.predict(test)\n",
    "xtest1['Survived'] = clf_test_predict\n",
    "xtest1[['PassengerId','Survived']].to_csv('M28.csv', index=False, float_format=\"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
