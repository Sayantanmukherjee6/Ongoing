{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['title', 'clf', 'table', 'test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=pd.read_csv('C:/Users/admin/Documents/Python Scripts/train.csv')\n",
    "#x.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#doing the same thing as we have done using Re ...\n",
    "def clean_cabin(x):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except TypeError:\n",
    "        return \"U\"\n",
    "    \n",
    "x['Cabin'] = x.Cabin.apply(clean_cabin)\n",
    "\n",
    "#x.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>U</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass              Name   Sex   Age  SibSp  Parch  Ticket  \\\n",
       "0          892       3  Kelly, Mr. James  male  34.5      0      0  330911   \n",
       "\n",
       "     Fare Cabin Embarked  \n",
       "0  7.8292     U        Q  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = pd.read_csv('C:/Users/admin/Documents/Python Scripts/test.csv')\n",
    "\n",
    "def clean_cabin(x):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except TypeError:\n",
    "        return \"U\"\n",
    "    \n",
    "xtest['Cabin'] = xtest.Cabin.apply(clean_cabin)\n",
    "\n",
    "xtest.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x.groupby(['Pclass','Cabin','Sex']).Cabin.count()\n",
    "#xtest.groupby(['Pclass','Cabin','Sex']).Cabin.count()\n",
    "x.loc[(x['Pclass'] == 1) & (x['Cabin'] == 'U'), 'Cabin'] = 'C'\n",
    "x.loc[(x['Pclass'] == 2) & (x['Cabin'] == 'U'), 'Cabin'] = 'E'\n",
    "x.loc[(x['Pclass'] == 3) & (x['Cabin'] == 'U') & (x['Sex'] == 'male') , 'Cabin'] = 'F'\n",
    "x.loc[(x['Pclass'] == 3) & (x['Cabin'] == 'U') & (x['Sex'] == 'female'),'Cabin'] = 'G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtest.loc[(xtest['Pclass'] == 1) & (xtest['Cabin'] == 'U'), 'Cabin'] = 'C'\n",
    "xtest.loc[(xtest['Pclass'] == 2) & (xtest['Cabin'] == 'U'), 'Cabin'] = 'E'\n",
    "xtest.loc[(xtest['Pclass'] == 3) & (xtest['Cabin'] == 'U') & (xtest['Sex'] == 'male') , 'Cabin'] = 'F'\n",
    "xtest.loc[(xtest['Pclass'] == 3) & (xtest['Cabin'] == 'U') & (xtest['Sex'] == 'female'),'Cabin'] = 'G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(x['Cabin'], prefix = 'Deck')\n",
    "x= pd.concat([x,dummies],axis =1)\n",
    "\n",
    "x.drop (['Cabin','Deck_T'],axis =1 ,inplace= True)\n",
    "\n",
    "dummies = pd.get_dummies(xtest['Cabin'], prefix = 'Deck')\n",
    "xtest= pd.concat([xtest,dummies],axis =1)\n",
    "\n",
    "xtest.drop (['Cabin'],axis =1 ,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Deck_A</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Sal_Master</th>\n",
       "      <th>Sal_Miss</th>\n",
       "      <th>Sal_Mr</th>\n",
       "      <th>Sal_Mrs</th>\n",
       "      <th>Family</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Age     Fare  Deck_A  Deck_B  Deck_C  Deck_D  Deck_E  \\\n",
       "0            1       3   22   7.2500       0       0       0       0       0   \n",
       "1            2       1   38  71.2833       0       0       1       0       0   \n",
       "\n",
       "   Deck_F     ...      Sal_Master  Sal_Miss  Sal_Mr  Sal_Mrs  Family  \\\n",
       "0       1     ...               0         0       1        0       1   \n",
       "1       0     ...               0         0       0        1       1   \n",
       "\n",
       "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0         1           0           0           1  \n",
       "1           1         0           1           0           0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def title(name):\n",
    "    temp_1 = name.split(',') # Split by (,)\n",
    "    temp_2 = temp_1[1].split('.')[0] # Split by (.)\n",
    "    temp_3 = temp_2.strip() # Remove white space\n",
    "    return temp_3\n",
    "\n",
    "x['Title'] = x['Name'].apply(title)\n",
    "\n",
    "x ['Temp'] =x['Sex'] + x['Title'] #just for female doctors\n",
    "x.loc[x['Temp'] == 'femaleDr', 'Title'] = 'Mrs' #just for female doctors\n",
    "\n",
    "x.drop ([ 'Temp' ],axis =1 ,inplace= True) #just for female doctors\n",
    "\n",
    "def new_title(title):\n",
    "    if title == 'Mr' or title == 'Capt' or title == 'Don' or title == 'Dr' or title == 'Jonkheer' or title     == 'Major' or  title == 'Rev' or title == 'Sir' or title == 'Col':\n",
    "        return 'Mr'\n",
    "    elif title == 'Mrs' or title == 'Lady' or title == 'Mme' or title == 'Ms' or title == 'the       Countess':\n",
    "        return 'Mrs'\n",
    "    elif title == 'Miss' or title == 'Mlle':\n",
    "        return 'Miss'\n",
    "    else:\n",
    "        return 'Master'\n",
    "    \n",
    "x['NewTitle'] = x['Title'].apply(new_title)\n",
    "\n",
    "dummies1 = pd.get_dummies(x['NewTitle'], prefix = 'Sal')\n",
    "x= pd.concat([x,dummies1],axis =1)\n",
    "#x.drop ([ 'Title' ],axis =1 ,inplace= True) # dropping some columns\n",
    "\n",
    "table = x.pivot_table(values='Age', index=['NewTitle'], columns=['Pclass', 'Sex'], aggfunc=np.median)\n",
    "# Define function to return value of this pivot_table\n",
    "def fage(age_calc):\n",
    "    return table [age_calc['Pclass']] [age_calc['Sex']] [age_calc['NewTitle']]\n",
    "# Replace missing values\n",
    "x['Age'].fillna(x[x['Age'].isnull()].apply(fage, axis=1), inplace=True)\n",
    "\n",
    "x['Family'] = x['SibSp'] + x['Parch']\n",
    "\n",
    "x['Fare'].fillna(x.Fare.mean(),inplace=True)\n",
    "\n",
    "dummies2 = pd.get_dummies(x['Sex'], prefix = 'Sex')\n",
    "x= pd.concat([x,dummies2],axis =1)\n",
    "dummies3 = pd.get_dummies(x['Embarked'], prefix = 'Embarked')\n",
    "x= pd.concat([x,dummies3],axis =1)\n",
    "\n",
    "\n",
    "x.drop (['Title','Name','SibSp','Parch','Ticket','NewTitle' ,'Sex','Embarked'],axis =1 ,inplace= True)\n",
    "\n",
    "y=x.pop('Survived')\n",
    "x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Deck_A</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Sal_Master</th>\n",
       "      <th>Sal_Miss</th>\n",
       "      <th>Sal_Mr</th>\n",
       "      <th>Sal_Mrs</th>\n",
       "      <th>Family</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass   Age    Fare  Deck_A  Deck_B  Deck_C  Deck_D  Deck_E  \\\n",
       "0          892       3  34.5  7.8292       0       0       0       0       0   \n",
       "1          893       3  47.0  7.0000       0       0       0       0       0   \n",
       "\n",
       "   Deck_F     ...      Sal_Master  Sal_Miss  Sal_Mr  Sal_Mrs  Family  \\\n",
       "0       1     ...               0         0       1        0       0   \n",
       "1       0     ...               0         0       0        1       1   \n",
       "\n",
       "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0         1           0           1           0  \n",
       "1           1         0           0           0           1  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def title(name):\n",
    "    temp_1 = name.split(',') # Split by (,)\n",
    "    temp_2 = temp_1[1].split('.')[0] # Split by (.)\n",
    "    temp_3 = temp_2.strip() # Remove white space\n",
    "    return temp_3\n",
    "\n",
    "xtest['Title'] = xtest['Name'].apply(title)\n",
    "\n",
    "def new_title(title):\n",
    "    if title == 'Mr' or title == 'Capt' or title == 'Don' or title == 'Dr' or title == 'Jonkheer' or title == 'Major' or  title == 'Rev' or title == 'Sir' or title == 'Col':\n",
    "        return 'Mr'\n",
    "    elif title == 'Mrs' or title == 'Lady' or title == 'Mme' or title == 'Ms' or title == 'the       Countess':\n",
    "        return 'Mrs'\n",
    "    elif title == 'Miss' or title == 'Mlle':\n",
    "        return 'Miss'\n",
    "    else:\n",
    "        return 'Master'\n",
    "    \n",
    "xtest['NewTitle'] = xtest['Title'].apply(new_title)\n",
    "\n",
    "dummies5 = pd.get_dummies(xtest['NewTitle'], prefix = 'Sal')\n",
    "xtest= pd.concat([xtest,dummies5],axis =1)\n",
    "\n",
    "\n",
    "table = xtest.pivot_table(values='Age', index=['NewTitle'], columns=['Pclass', 'Sex'], aggfunc=np.median)\n",
    "# Define function to return value of this pivot_table\n",
    "def fage2(age_calc):\n",
    "    return table [age_calc['Pclass']] [age_calc['Sex']] [age_calc['NewTitle']]\n",
    "# Replace missing values\n",
    "xtest['Age'].fillna(xtest[xtest['Age'].isnull()].apply(fage, axis=1), inplace=True)\n",
    "\n",
    "xtest['Family'] = xtest['SibSp'] + xtest['Parch']\n",
    "\n",
    "xtest['Fare'].fillna(x.Fare.mean(),inplace=True)\n",
    "\n",
    "dummies6 = pd.get_dummies(xtest['Sex'], prefix = 'Sex')\n",
    "xtest= pd.concat([xtest,dummies6],axis =1)\n",
    "dummies7 = pd.get_dummies(xtest['Embarked'], prefix = 'Embarked')\n",
    "xtest= pd.concat([xtest,dummies7],axis =1)\n",
    "\n",
    "\n",
    "xtest.drop (['Title','Name','SibSp','Parch','Ticket','NewTitle' ,'Sex','Embarked'],axis =1 ,inplace= True)\n",
    "\n",
    "\n",
    "xtest.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification and Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 21)\n",
      "(418, 21)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=x.values\n",
    "target=y.values\n",
    "xtest1=xtest\n",
    "test=xtest.values\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821229050279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821229050279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.810055865922\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=90)\n",
    "clf.fit(X_train, y_train)\n",
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815642458101\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel ='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel ='linear')\n",
    "clf = clf.fit(train,target)\n",
    "clf_test_predict = clf.predict(test)\n",
    "xtest1['Survived'] = clf_test_predict\n",
    "xtest1[['PassengerId','Survived']].to_csv('M1.csv', index=False, float_format=\"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_stat:  0.878204923359\n"
     ]
    }
   ],
   "source": [
    "#from titanic-5 example we calculated the three parameters\n",
    "rr = RandomForestRegressor(n_estimators = 500,\n",
    "                             max_features='auto',\n",
    "                             oob_score =True,\n",
    "                             min_samples_leaf=4,\n",
    "                             random_state =42)\n",
    "\n",
    "rr.fit(x,y)\n",
    "roc = roc_auc_score(y, rr.oob_prediction_)\n",
    "print \"C_stat: \", roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815642458101\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 500,\n",
    "                             max_features='auto',\n",
    "                             min_samples_leaf=4,\n",
    "                             random_state =42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 500,\n",
    "                             max_features='auto',\n",
    "                             min_samples_leaf=4,\n",
    "                             random_state =41)\n",
    "clf = clf.fit(train,target)\n",
    "clf_test_predict = clf.predict(test)\n",
    "xtest1['Survived'] = clf_test_predict\n",
    "xtest1[['PassengerId','Survived']].to_csv('M2.csv', index=False, float_format=\"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(train,target)\n",
    "clf_test_predict = clf.predict(test)\n",
    "xtest1['Survived'] = clf_test_predict\n",
    "xtest1[['PassengerId','Survived']].to_csv('M3.csv', index=False, float_format=\"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf = clf.fit(train,target)\n",
    "clf_test_predict = clf.predict(test)\n",
    "xtest1['Survived'] = clf_test_predict\n",
    "xtest1[['PassengerId','Survived']].to_csv('M4.csv', index=False, float_format=\"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using Grid search for finding the best RF parameters\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "parameter_grid = {\n",
    "    'max_features': [0.5, 1.],\n",
    "    'max_depth': [5., None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(n_estimators = 100), parameter_grid,\n",
    "                            cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.709497 -   0.0s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.821229 -   0.0s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.831461 -   0.0s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.792135 -   0.0s\n",
      "[CV] max_features=0.5, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=0.5, max_depth=5.0, score=0.864407 -   0.0s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.687151 -   0.1s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.821229 -   0.1s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.825843 -   0.1s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.797753 -   0.1s\n",
      "[CV] max_features=1.0, max_depth=5.0 .................................\n",
      "[CV] ........ max_features=1.0, max_depth=5.0, score=0.864407 -   0.1s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.670391 -   0.1s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.821229 -   0.1s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.848315 -   0.1s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.825843 -   0.1s\n",
      "[CV] max_features=0.5, max_depth=None ................................\n",
      "[CV] ....... max_features=0.5, max_depth=None, score=0.853107 -   0.1s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.614525 -   0.1s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.815642 -   0.1s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.859551 -   0.1s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.837079 -   0.1s\n",
      "[CV] max_features=1.0, max_depth=None ................................\n",
      "[CV] ....... max_features=1.0, max_depth=None, score=0.858757 -   0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'max_features': [0.5, 1.0], 'max_depth': [5.0, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=3)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.80359, std: 0.05248, params: {'max_features': 0.5, 'max_depth': 5.0},\n",
       " mean: 0.79910, std: 0.06001, params: {'max_features': 1.0, 'max_depth': 5.0},\n",
       " mean: 0.80359, std: 0.06782, params: {'max_features': 0.5, 'max_depth': None},\n",
       " mean: 0.79686, std: 0.09271, params: {'max_features': 1.0, 'max_depth': None}]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5.0, 'max_features': 0.5}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "grid_search.best_score_\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821229050279\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 100,\n",
    "                               max_features=0.5, \n",
    "                               max_depth=5.0)\n",
    "#clf = clf.fit(train,target)\n",
    "#clf_test_predict = clf.predict(test)\n",
    "#xtest1['Survived'] = clf_test_predict\n",
    "#xtest1[['PassengerId','Survived']].to_csv('M4.csv', index=False, float_format=\"%f\")\n",
    "clf.fit(X_train, y_train)\n",
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the parameter grid for SVC, noting that the default parameters are C = 1.0, and  gamma = 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] C=1.0, gamma=0.1 ................................................\n",
      "[CV] ....................... C=1.0, gamma=0.1, score=0.843575 -  33.4s\n",
      "[CV] C=1.0, gamma=0.1 ................................................\n",
      "[CV] ....................... C=1.0, gamma=0.1, score=0.826816 -  54.3s\n",
      "[CV] C=1.0, gamma=0.1 ................................................\n",
      "[CV] ....................... C=1.0, gamma=0.1, score=0.825843 -  49.1s\n",
      "[CV] C=1.0, gamma=0.1 ................................................\n",
      "[CV] ....................... C=1.0, gamma=0.1, score=0.808989 -  53.7s\n",
      "[CV] C=1.0, gamma=0.1 ................................................\n",
      "[CV] ....................... C=1.0, gamma=0.1, score=0.875706 - 1.3min\n",
      "[CV] C=1.0, gamma=1.0 ................................................\n",
      "[CV] ....................... C=1.0, gamma=1.0, score=0.843575 -  33.8s\n",
      "[CV] C=1.0, gamma=1.0 ................................................\n",
      "[CV] ....................... C=1.0, gamma=1.0, score=0.826816 -  54.3s\n",
      "[CV] C=1.0, gamma=1.0 ................................................\n",
      "[CV] ....................... C=1.0, gamma=1.0, score=0.825843 -  49.0s\n",
      "[CV] C=1.0, gamma=1.0 ................................................\n",
      "[CV] ....................... C=1.0, gamma=1.0, score=0.808989 -  53.4s\n",
      "[CV] C=1.0, gamma=1.0 ................................................\n",
      "[CV] ....................... C=1.0, gamma=1.0, score=0.875706 - 1.3min\n",
      "[CV] C=10.0, gamma=0.1 ...............................................\n",
      "[CV] ...................... C=10.0, gamma=0.1, score=0.787709 -  43.7s\n",
      "[CV] C=10.0, gamma=0.1 ...............................................\n",
      "[CV] ...................... C=10.0, gamma=0.1, score=0.804469 - 2.3min\n",
      "[CV] C=10.0, gamma=0.1 ...............................................\n",
      "[CV] ...................... C=10.0, gamma=0.1, score=0.848315 - 1.9min\n",
      "[CV] C=10.0, gamma=0.1 ...............................................\n",
      "[CV] ...................... C=10.0, gamma=0.1, score=0.786517 - 1.8min\n",
      "[CV] C=10.0, gamma=0.1 ...............................................\n",
      "[CV] ...................... C=10.0, gamma=0.1, score=0.870056 - 2.5min\n",
      "[CV] C=10.0, gamma=1.0 ...............................................\n",
      "[CV] ...................... C=10.0, gamma=1.0, score=0.787709 -  41.4s\n",
      "[CV] C=10.0, gamma=1.0 ...............................................\n",
      "[CV] ...................... C=10.0, gamma=1.0, score=0.804469 - 2.2min\n",
      "[CV] C=10.0, gamma=1.0 ...............................................\n",
      "[CV] ...................... C=10.0, gamma=1.0, score=0.848315 - 1.9min\n",
      "[CV] C=10.0, gamma=1.0 ...............................................\n",
      "[CV] ...................... C=10.0, gamma=1.0, score=0.786517 - 1.7min\n",
      "[CV] C=10.0, gamma=1.0 ...............................................\n",
      "[CV] ...................... C=10.0, gamma=1.0, score=0.870056 - 2.5min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:   33.4s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 27.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'C': [1.0, 10.0], 'gamma': [0.1, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=3)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "parameter_grid = {\n",
    "    'C': [1., 10.],\n",
    "    'gamma': [0.1, 1.]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(kernel='linear'), parameter_grid, cv=5, verbose=3)\n",
    "grid_search.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'gamma': 0.1}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "grid_search.best_score_\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear', C=1.0, gamma=0.1)\n",
    "clf = clf.fit(train,target)\n",
    "clf_test_predict = clf.predict(xtest1)\n",
    "xtest1['Survived'] = clf_test_predict\n",
    "xtest1[['PassengerId','Survived']].to_csv('M5.csv', index=False, float_format=\"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 22)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtest1.drop (['Survived'],axis =1 ,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 21)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 21)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 21)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
